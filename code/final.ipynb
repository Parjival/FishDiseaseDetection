import os
import pandas as pd
import numpy as np
try:
    import torch
    print(f"PyTorch version: {torch.__version__}")
except ImportError as e:
    print(f"Error importing torch: {e}. Please reinstall PyTorch.")
    exit()
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models, datasets, transforms
from torchvision.models import ResNet50_Weights, EfficientNet_B3_Weights
from transformers import ViTForImageClassification, ViTImageProcessor
from PIL import Image
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, roc_curve, auc
import seaborn as sns
import matplotlib.pyplot as plt
import albumentations as A
from albumentations.pytorch import ToTensorV2
from tabulate import tabulate
from torchsummary import summary

# Set random seed for reproducibility
torch.manual_seed(42)
np.random.seed(42)

# Device configuration with fallback
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Define paths
data_dir = "/kaggle/input/fish-disease-detection-dataset/New Dataset"
train_dir = os.path.join(data_dir, "train_split")
test_dir = os.path.join(data_dir, "test_split")
test_csv = os.path.join(data_dir, "test.csv")

# Define class labels
class_names = [
    "Bacterial Red disease", "Bacterial diseases - Aeromoniasis", "Bacterial gill disease",
    "EUS", "Fungal diseases Saprolegniasis", "Healthy Fish", "Parasitic diseases", "Viral diseases White tail disease"
]
num_classes = len(class_names)
class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}

# Data augmentation and preprocessing
train_transforms = A.Compose([
    A.Resize(224, 224),
    A.RandomCrop(200, 200, p=0.5),
    A.Resize(224, 224),
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.2),
    A.Rotate(limit=30, p=0.5),
    ToTensorV2()
])

test_transforms = A.Compose([
    A.Resize(224, 224),
    ToTensorV2()
])

# Custom Dataset for test set
class TestDataset(Dataset):
    def __init__(self, csv_file, img_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        self.label_to_idx = class_to_idx

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_name = os.path.join(self.img_dir, self.data.iloc[idx]["filename"])
        image = Image.open(img_name).convert("RGB")
        label = self.label_to_idx[self.data.iloc[idx]["label"]]
        
        image = np.array(image)
        if self.transform:
            augmented = self.transform(image=image)
            image = augmented["image"]
        
        return image, label

# Load datasets
train_dataset = datasets.ImageFolder(
    train_dir,
    transform=lambda x: train_transforms(image=np.array(x))["image"]
)
test_dataset = TestDataset(test_csv, test_dir, transform=test_transforms)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)

# Split train into train and validation
train_size = int(0.8 * len(train_dataset))
val_size = len(train_dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)

# Define ensemble models
def get_model(model_name):
    if model_name == "resnet50":
        model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)
        model.fc = nn.Linear(model.fc.in_features, num_classes)
    elif model_name == "efficientnet_b3":
        model = models.efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1)
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    elif model_name == "vit":
        model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')
        model.classifier = nn.Linear(model.classifier.in_features, num_classes)
    return model.to(device)

models_list = ["resnet50", "efficientnet_b3", "vit"]
ensemble_models = [get_model(name) for name in models_list]

# Preprocess for ViT
def preprocess_vit(images):
    processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')
    images_pil = [Image.fromarray((img.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)) for img in images]
    return processor(images=images_pil, return_tensors="pt")

# Training function for ensemble with combined epochs
def train_ensemble(models, train_loader, val_loader, num_epochs=30):
    criterion = nn.CrossEntropyLoss()
    optimizers = [optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2) for model in models]
    schedulers = [optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs) for optimizer in optimizers]
    
    train_losses = {model_name: [] for model_name in models_list}
    val_losses = {model_name: [] for model_name in models_list}
    train_accs = {model_name: [] for model_name in models_list}
    val_accs = {model_name: [] for model_name in models_list}
    
    for epoch in range(num_epochs):
        for model_name, model in zip(models_list, models):
            model.train()
            running_loss = 0.0
            correct = 0
            total = 0
            for inputs, labels in train_loader:
                inputs = inputs.float().to(device)
                labels = labels.to(device)
                optimizer = optimizers[models_list.index(model_name)]
                optimizer.zero_grad()
                if isinstance(model, ViTForImageClassification):
                    inputs_vit = preprocess_vit(inputs)
                    inputs_vit = {k: v.to(device) for k, v in inputs_vit.items()}
                    outputs = model(**inputs_vit).logits
                else:
                    outputs = model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                running_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
            
            train_loss = running_loss / len(train_loader)
            train_acc = correct / total
            train_losses[model_name].append(train_loss)
            train_accs[model_name].append(train_acc)
        
        # Validation for all models
        for model_name, model in zip(models_list, models):
            model.eval()
            val_loss = 0.0
            correct = 0
            total = 0
            with torch.no_grad():
                for inputs, labels in val_loader:
                    inputs = inputs.float().to(device)
                    labels = labels.to(device)
                    if isinstance(model, ViTForImageClassification):
                        inputs_vit = preprocess_vit(inputs)
                        inputs_vit = {k: v.to(device) for k, v in inputs_vit.items()}
                        outputs = model(**inputs_vit).logits
                    else:
                        outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    val_loss += loss.item()
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()
            
            val_loss = val_loss / len(val_loader)
            val_acc = correct / total
            val_losses[model_name].append(val_loss)
            val_accs[model_name].append(val_acc)
        
        for scheduler in schedulers:
            scheduler.step()
        print(f"Epoch {epoch+1}, "
              f"ResNet50 Train Loss: {train_losses['resnet50'][-1]:.4f}, Train Acc: {train_accs['resnet50'][-1]:.4f}, Val Loss: {val_losses['resnet50'][-1]:.4f}, Val Acc: {val_accs['resnet50'][-1]:.4f}, "
              f"EfficientNet-B3 Train Loss: {train_losses['efficientnet_b3'][-1]:.4f}, Train Acc: {train_accs['efficientnet_b3'][-1]:.4f}, Val Loss: {val_losses['efficientnet_b3'][-1]:.4f}, Val Acc: {val_accs['efficientnet_b3'][-1]:.4f}, "
              f"ViT Train Loss: {train_losses['vit'][-1]:.4f}, Train Acc: {train_accs['vit'][-1]:.4f}, Val Loss: {val_losses['vit'][-1]:.4f}, Val Acc: {val_accs['vit'][-1]:.4f}")
    
    return train_losses, val_losses, train_accs, val_accs

# Train the ensemble with 30 combined epochs
train_losses, val_losses, train_accs, val_accs = train_ensemble(ensemble_models, train_loader, val_loader, num_epochs=30)

# Plot training and validation loss
plt.figure(figsize=(10, 5))
for model_name in models_list:
    plt.plot(train_losses[model_name], label=f'{model_name} Train Loss')
    plt.plot(val_losses[model_name], label=f'{model_name} Val Loss', linestyle='--')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.savefig('loss_graph.png')
plt.close()

# Plot training and validation accuracy
plt.figure(figsize=(10, 5))
for model_name in models_list:
    plt.plot(train_accs[model_name], label=f'{model_name} Train Acc')
    plt.plot(val_accs[model_name], label=f'{model_name} Val Acc', linestyle='--')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.savefig('accuracy_graph.png')
plt.close()

# Ensemble prediction with metrics
def ensemble_evaluate(models, loader):
    predictions = []
    true_labels = []
    probas = []
    
    for model in models:
        model.eval()
    
    with torch.no_grad():
        for inputs, labels in loader:
            inputs = inputs.float().to(device)
            labels = labels.to(device)
            true_labels.extend(labels.cpu().numpy())
            avg_probas = torch.zeros(inputs.size(0), num_classes).to(device)
            
            for i, model in enumerate(models):
                if isinstance(model, ViTForImageClassification):
                    inputs_vit = preprocess_vit(inputs)
                    inputs_vit = {k: v.to(device) for k, v in inputs_vit.items()}
                    outputs = model(**inputs_vit).logits
                else:
                    outputs = model(inputs)
                avg_probas += torch.softmax(outputs, dim=1) / len(models)
            
            _, preds = torch.max(avg_probas, 1)
            predictions.extend(preds.cpu().numpy())
            probas.append(avg_probas.cpu().numpy())
    
    probas = np.concatenate(probas)
    accuracy = accuracy_score(true_labels, predictions)
    f1 = f1_score(true_labels, predictions, average='weighted')
    precision = precision_score(true_labels, predictions, average='weighted')
    cm = confusion_matrix(true_labels, predictions)
    
    print(f"Test Accuracy: {accuracy*100:.2f}%")
    print(f"Test F1 Score: {f1:.4f}")
    print(f"Test Precision: {precision:.4f}")
    
    return true_labels, predictions, probas, cm

# Evaluate ensemble and store results
test_true, test_pred, test_probas, cm = ensemble_evaluate(ensemble_models, test_loader)
accuracy, f1, precision = accuracy_score(test_true, test_pred), f1_score(test_true, test_pred, average='weighted'), precision_score(test_true, test_pred, average='weighted')

# Confusion Matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix (Test Set)')
plt.savefig('confusion_matrix.png')
plt.close()

# ROC Curve
plt.figure(figsize=(10, 8))
for i in range(num_classes):
    fpr, tpr, _ = roc_curve(np.array(test_true) == i, test_probas[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Multi-class ROC Curve')
plt.legend(loc="lower right")
plt.savefig('roc_curve.png')
plt.close()

# Save metrics to CSV
metrics = {
    'Test Accuracy': accuracy,
    'Test F1 Score': f1,
    'Test Precision': precision
}

with open('metrics.csv', 'w', newline='') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=metrics.keys())
    writer.writeheader()
    writer.writerow(metrics)

# Generate summary report
table = [
    ["Metric", "Value"],
    ["Test Accuracy", f"{accuracy*100:.2f}%"],
    ["Test F1 Score", f"{f1:.4f}"],
    ["Test Precision", f"{precision:.4f}"]
]

print("\nSummary of Experimental Results:")
print(tabulate(table, headers="firstrow", tablefmt="grid"))

# Dataset statistics
train_class_counts = np.bincount([label for _, label in train_dataset])
val_class_counts = np.bincount([label for _, label in val_dataset])
test_class_counts = np.bincount([label for _, label in test_dataset])

print("\nDataset Statistics:")
print("Training set size:", len(train_dataset))
print("Validation set size:", len(val_dataset))
print("Test set size:", len(test_dataset))

print("\nClass distribution in training set:")
for i, count in enumerate(train_class_counts):
    print(f"{class_names[i]}: {count}")

print("\nClass distribution in validation set:")
for i, count in enumerate(val_class_counts):
    print(f"{class_names[i]}: {count}")

print("\nClass distribution in test set:")
for i, count in enumerate(test_class_counts):
    print(f"{class_names[i]}: {count}")

# Model architecture summary
print("\nModel Architecture Summaries:")
for model_name, model in zip(models_list, ensemble_models):
    if model_name != "vit":
        print(f"\nModel: {model_name}")
        summary(model, input_size=(3, 224, 224))
    else:
        print(f"\nModel: {model_name} - Summary not available for ViT due to transformer structure")

# Save models
for i, model in enumerate(ensemble_models):
    torch.save(model.state_dict(), f"model_{models_list[i]}.pth")
